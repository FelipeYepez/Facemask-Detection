{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(seed):\n",
    "    nTotal = 20000\n",
    "    \n",
    "    X = np.zeros((nTotal, 784))\n",
    "    Y = np.zeros((nTotal, 2))\n",
    "    count = 0\n",
    "    for dirname, _, filenames in os.walk('Datasets'):\n",
    "        for filename in filenames:\n",
    "            image = Image.open(os.path.join(dirname, filename)).resize((28,28))\n",
    "            \n",
    "            data = np.asarray(image, dtype='float64').reshape(1, -1)\n",
    "\n",
    "            data = data / 255\n",
    "            \n",
    "            X[count] = data\n",
    "            if count == 0:\n",
    "                print(\"Data shape \", data.shape)\n",
    "                print(data)\n",
    "                plt.imshow(image)\n",
    "            if(count < nTotal / 2):\n",
    "                # Y[count] = 0\n",
    "                Y[count] = np.array([1, 0])\n",
    "            elif(count < nTotal):\n",
    "                # Y[count] = 1\n",
    "                Y[count] = np.array([0, 1])\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    indices = list(np.random.permutation(nTotal))\n",
    "    X = X[indices]\n",
    "    Y = Y[indices]\n",
    "\n",
    "    nTrain = int(nTotal * 0.9)\n",
    "    nDev = int(nTotal * 0.05)\n",
    "    nTest = int(nTotal * 0.05)\n",
    "\n",
    "    trainX = X[: nTrain]\n",
    "    trainY = Y[: nTrain]\n",
    "    \n",
    "    devX = X[nTrain : nDev]\n",
    "    devY = Y[nTrain : nDev]\n",
    "\n",
    "    testX = X[nDev : nTest]\n",
    "    testY = Y[nDev : nTest]\n",
    "    \n",
    "    return trainX.T, trainY.T, devX.T, devY.T, testX.T, testY.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape  (1, 784)\n",
      "[[0.6        0.60392157 0.60392157 0.60784314 0.60392157 0.60392157\n",
      "  0.60392157 0.60392157 0.58431373 0.54117647 0.5254902  0.53333333\n",
      "  0.50980392 0.49411765 0.51764706 0.57254902 0.60392157 0.61176471\n",
      "  0.61568627 0.62745098 0.62352941 0.62352941 0.62352941 0.61960784\n",
      "  0.61960784 0.61960784 0.63529412 0.63921569 0.60784314 0.60784314\n",
      "  0.6        0.60784314 0.60784314 0.61176471 0.6        0.54509804\n",
      "  0.50980392 0.40392157 0.37254902 0.35294118 0.30980392 0.29411765\n",
      "  0.3372549  0.43529412 0.52156863 0.60784314 0.62745098 0.61960784\n",
      "  0.62745098 0.63137255 0.63137255 0.62352941 0.61960784 0.61960784\n",
      "  0.63529412 0.63137255 0.60784314 0.61568627 0.60392157 0.61176471\n",
      "  0.62352941 0.61176471 0.4627451  0.40392157 0.38823529 0.31372549\n",
      "  0.28627451 0.28627451 0.3254902  0.34509804 0.35294118 0.36862745\n",
      "  0.41568627 0.49019608 0.56078431 0.62352941 0.63529412 0.63529412\n",
      "  0.62745098 0.63137255 0.61960784 0.62745098 0.62352941 0.62745098\n",
      "  0.58039216 0.58823529 0.6        0.6        0.62352941 0.49019608\n",
      "  0.36470588 0.40392157 0.35686275 0.38039216 0.3372549  0.23529412\n",
      "  0.21568627 0.25490196 0.3254902  0.36862745 0.39607843 0.41960784\n",
      "  0.44705882 0.54509804 0.63137255 0.63137255 0.62352941 0.61568627\n",
      "  0.61176471 0.62745098 0.61960784 0.62352941 0.6        0.61568627\n",
      "  0.61960784 0.61568627 0.54117647 0.36470588 0.36078431 0.3372549\n",
      "  0.34901961 0.40784314 0.46666667 0.38431373 0.34117647 0.2627451\n",
      "  0.26666667 0.34901961 0.36862745 0.37647059 0.39215686 0.45490196\n",
      "  0.57254902 0.64313725 0.63921569 0.63137255 0.63137255 0.62745098\n",
      "  0.62745098 0.61960784 0.61176471 0.62745098 0.63137255 0.61176471\n",
      "  0.39215686 0.35686275 0.30196078 0.30588235 0.36470588 0.54117647\n",
      "  0.6745098  0.69803922 0.68627451 0.61960784 0.47843137 0.37254902\n",
      "  0.33333333 0.31372549 0.34117647 0.36862745 0.46666667 0.60392157\n",
      "  0.64313725 0.63921569 0.63921569 0.63921569 0.63529412 0.61568627\n",
      "  0.61176471 0.61960784 0.63137255 0.5372549  0.3254902  0.30980392\n",
      "  0.2745098  0.31372549 0.50588235 0.70588235 0.75294118 0.75294118\n",
      "  0.74509804 0.74509804 0.7254902  0.6745098  0.49019608 0.28235294\n",
      "  0.2627451  0.30588235 0.35294118 0.49019608 0.63529412 0.63529412\n",
      "  0.63921569 0.64313725 0.62745098 0.62352941 0.61176471 0.61176471\n",
      "  0.62745098 0.43921569 0.2627451  0.24705882 0.23921569 0.45098039\n",
      "  0.68235294 0.73333333 0.74901961 0.75294118 0.74509804 0.74901961\n",
      "  0.75294118 0.75294118 0.72156863 0.49803922 0.23137255 0.23137255\n",
      "  0.28235294 0.36470588 0.58039216 0.65490196 0.65098039 0.64313725\n",
      "  0.61960784 0.62745098 0.61176471 0.61176471 0.60392157 0.36078431\n",
      "  0.20784314 0.19215686 0.3254902  0.62745098 0.7372549  0.73333333\n",
      "  0.74117647 0.74901961 0.74901961 0.74509804 0.74901961 0.74509804\n",
      "  0.7372549  0.70980392 0.39215686 0.18039216 0.22352941 0.29019608\n",
      "  0.48627451 0.65098039 0.64705882 0.63921569 0.62352941 0.63529412\n",
      "  0.60784314 0.61568627 0.56470588 0.2745098  0.13333333 0.14117647\n",
      "  0.40392157 0.67058824 0.74509804 0.75686275 0.76470588 0.76470588\n",
      "  0.75294118 0.75294118 0.75294118 0.75686275 0.75686275 0.76862745\n",
      "  0.6627451  0.24313725 0.18823529 0.24313725 0.36862745 0.61568627\n",
      "  0.64705882 0.65882353 0.6627451  0.65490196 0.60392157 0.61568627\n",
      "  0.51372549 0.18823529 0.08627451 0.16470588 0.44313725 0.68235294\n",
      "  0.70980392 0.66666667 0.64313725 0.6745098  0.72156863 0.73333333\n",
      "  0.73333333 0.72941176 0.70980392 0.6745098  0.67843137 0.43529412\n",
      "  0.16862745 0.22352941 0.27843137 0.54509804 0.65098039 0.6627451\n",
      "  0.6627451  0.65098039 0.61960784 0.62352941 0.4627451  0.13333333\n",
      "  0.09019608 0.19607843 0.56470588 0.6745098  0.64313725 0.61176471\n",
      "  0.50196078 0.43921569 0.57647059 0.68235294 0.70196078 0.63921569\n",
      "  0.48627451 0.45490196 0.59215686 0.54509804 0.21176471 0.21176471\n",
      "  0.22745098 0.43529412 0.64313725 0.64313725 0.64313725 0.64705882\n",
      "  0.62745098 0.62352941 0.39215686 0.09803922 0.07843137 0.25098039\n",
      "  0.6627451  0.6745098  0.56078431 0.38431373 0.3372549  0.40784314\n",
      "  0.49019608 0.67058824 0.72941176 0.55294118 0.37647059 0.32156863\n",
      "  0.40392157 0.54509804 0.28235294 0.19215686 0.21176471 0.34117647\n",
      "  0.62352941 0.64313725 0.63921569 0.63921569 0.62352941 0.60784314\n",
      "  0.32941176 0.11372549 0.10588235 0.36862745 0.70980392 0.65882353\n",
      "  0.43921569 0.32156863 0.34117647 0.45098039 0.50196078 0.69803922\n",
      "  0.76862745 0.56470588 0.40392157 0.34117647 0.37254902 0.43137255\n",
      "  0.35294118 0.17254902 0.18823529 0.27058824 0.57254902 0.65882353\n",
      "  0.64313725 0.63137255 0.61960784 0.59215686 0.29019608 0.17254902\n",
      "  0.25490196 0.46666667 0.7254902  0.72156863 0.70196078 0.63529412\n",
      "  0.59215686 0.6        0.65882353 0.70980392 0.75294118 0.6745098\n",
      "  0.61568627 0.58823529 0.61960784 0.67058824 0.49019608 0.14117647\n",
      "  0.16078431 0.22352941 0.49019608 0.65098039 0.63921569 0.63529412\n",
      "  0.61176471 0.56862745 0.26666667 0.18823529 0.35686275 0.52156863\n",
      "  0.70980392 0.73333333 0.76078431 0.76470588 0.75686275 0.76078431\n",
      "  0.72156863 0.71764706 0.76470588 0.72156863 0.74901961 0.76078431\n",
      "  0.76862745 0.75686275 0.61960784 0.14509804 0.14117647 0.19215686\n",
      "  0.41176471 0.64313725 0.63529412 0.63137255 0.61176471 0.54117647\n",
      "  0.2627451  0.21568627 0.43137255 0.54509804 0.69019608 0.72941176\n",
      "  0.76078431 0.78039216 0.78039216 0.70980392 0.67058824 0.7254902\n",
      "  0.77647059 0.7254902  0.68627451 0.76078431 0.78431373 0.76078431\n",
      "  0.63137255 0.14901961 0.12156863 0.17647059 0.34901961 0.60784314\n",
      "  0.63529412 0.62352941 0.61176471 0.51764706 0.25882353 0.18431373\n",
      "  0.46666667 0.59607843 0.67058824 0.72156863 0.74117647 0.73333333\n",
      "  0.69803922 0.58431373 0.61960784 0.63529412 0.66666667 0.62352941\n",
      "  0.59607843 0.63137255 0.72156863 0.73333333 0.56470588 0.11764706\n",
      "  0.12156863 0.16078431 0.30196078 0.54509804 0.63137255 0.61960784\n",
      "  0.60392157 0.48627451 0.2627451  0.16470588 0.30980392 0.58431373\n",
      "  0.66666667 0.69411765 0.69411765 0.66666667 0.58431373 0.61960784\n",
      "  0.59607843 0.52941176 0.5254902  0.56470588 0.63921569 0.56078431\n",
      "  0.60784314 0.64313725 0.5372549  0.15294118 0.12941176 0.15686275\n",
      "  0.28627451 0.49411765 0.62352941 0.61568627 0.60392157 0.45882353\n",
      "  0.2745098  0.17647059 0.11372549 0.25490196 0.61960784 0.69803922\n",
      "  0.65882353 0.59607843 0.56862745 0.65882353 0.65882353 0.61960784\n",
      "  0.61176471 0.65098039 0.65882353 0.58823529 0.56078431 0.60392157\n",
      "  0.49411765 0.15294118 0.14901961 0.16078431 0.2745098  0.4627451\n",
      "  0.61568627 0.61176471 0.60392157 0.41960784 0.27058824 0.20392157\n",
      "  0.10980392 0.14901961 0.49803922 0.71372549 0.6745098  0.6627451\n",
      "  0.51764706 0.40784314 0.50588235 0.54901961 0.54509804 0.50196078\n",
      "  0.39215686 0.52941176 0.65882353 0.65882353 0.36862745 0.11764706\n",
      "  0.17254902 0.17254902 0.25882353 0.43137255 0.59607843 0.60392157\n",
      "  0.59215686 0.40392157 0.25882353 0.21568627 0.12156863 0.12941176\n",
      "  0.30980392 0.69411765 0.67843137 0.67843137 0.6627451  0.62352941\n",
      "  0.56470588 0.58039216 0.58823529 0.58039216 0.61176471 0.68235294\n",
      "  0.67843137 0.64705882 0.2        0.2        0.20784314 0.18431373\n",
      "  0.25490196 0.40392157 0.56862745 0.6        0.58823529 0.42352941\n",
      "  0.25098039 0.23137255 0.14901961 0.09411765 0.13333333 0.58823529\n",
      "  0.67058824 0.65490196 0.68627451 0.68235294 0.65490196 0.6\n",
      "  0.59607843 0.63529412 0.69019608 0.69803922 0.6627451  0.47058824\n",
      "  0.05490196 0.18431373 0.23137255 0.2        0.24705882 0.38823529\n",
      "  0.5372549  0.59607843 0.58823529 0.41960784 0.23921569 0.24313725\n",
      "  0.16078431 0.10980392 0.10980392 0.47843137 0.63137255 0.66666667\n",
      "  0.70196078 0.71372549 0.70980392 0.72941176 0.72941176 0.7254902\n",
      "  0.7254902  0.69411765 0.56470588 0.14117647 0.04705882 0.1254902\n",
      "  0.23137255 0.22745098 0.23137255 0.39215686 0.50196078 0.57647059\n",
      "  0.58039216 0.40784314 0.25098039 0.24313725 0.18823529 0.11764706\n",
      "  0.09803922 0.43137255 0.57254902 0.59607843 0.64705882 0.70980392\n",
      "  0.73333333 0.7372549  0.74509804 0.74117647 0.69803922 0.58431373\n",
      "  0.28235294 0.03529412 0.07843137 0.1254902  0.23137255 0.24313725\n",
      "  0.23137255 0.37647059 0.48235294 0.56078431 0.57647059 0.41960784\n",
      "  0.26666667 0.23921569 0.22352941 0.1372549  0.11372549 0.36078431\n",
      "  0.60784314 0.54117647 0.5372549  0.57254902 0.61176471 0.61960784\n",
      "  0.62352941 0.61176471 0.52941176 0.52941176 0.23137255 0.05882353\n",
      "  0.08627451 0.13333333 0.22352941 0.24705882 0.23529412 0.34509804\n",
      "  0.4745098  0.54901961 0.58039216 0.45490196 0.27843137 0.22352941\n",
      "  0.25882353 0.16470588 0.12156863 0.30588235 0.61960784 0.60392157\n",
      "  0.56470588 0.54901961 0.5254902  0.50588235 0.50196078 0.50980392\n",
      "  0.54509804 0.57254902 0.21176471 0.07843137 0.09019608 0.1254902\n",
      "  0.21960784 0.24313725 0.23137255 0.31764706 0.47058824 0.54901961\n",
      "  0.58039216 0.4627451  0.2745098  0.21960784 0.2745098  0.18823529\n",
      "  0.13333333 0.24313725 0.60392157 0.64705882 0.6        0.61960784\n",
      "  0.60392157 0.57647059 0.58039216 0.60392157 0.60392157 0.55294118\n",
      "  0.19215686 0.09411765 0.09019608 0.1372549  0.22352941 0.24705882\n",
      "  0.21176471 0.29019608 0.43137255 0.51764706]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainX, trainY, devX, devY, testX, testY = load_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    W2 = np.random.rand(2, 10) - 0.5\n",
    "    b2 = np.random.rand(2, 1) - 0.5\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "    \n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, int(Y.max()) + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    # print(\"One hot Y\", one_hot_Y)\n",
    "    # print(\"One hot Y shape\", one_hot_Y.shape)\n",
    "    return one_hot_Y\n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y, prin):\n",
    "    m = X.shape[1]\n",
    "    # one_hot_Y = one_hot(Y)\n",
    "    one_hot_Y = Y\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2)\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1    \n",
    "    W2 = W2 - alpha * dW2  \n",
    "    b2 = b2 - alpha * db2    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.rint(A2)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def real_accurracy(A2, Y):\n",
    "    total = 0\n",
    "    for i in range(18000):\n",
    "        if A2[0, i] > A2[1, i] and Y[0, i] == 1:\n",
    "            total += 1\n",
    "        elif A2[0, i] < A2[1, i] and Y[1, i] == 1:\n",
    "            total += 1\n",
    "    return total / (Y.size / 2)\n",
    "\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        prin = False\n",
    "        if i == iterations - 1:\n",
    "            prin = True\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y, prin)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "            # print(real_accurracy(A2, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "0.5092222222222222\n",
      "Iteration:  10\n",
      "0.783\n",
      "Iteration:  20\n",
      "0.8908888888888888\n",
      "Iteration:  30\n",
      "0.9322222222222222\n",
      "Iteration:  40\n",
      "0.8486666666666667\n",
      "Iteration:  50\n",
      "0.9306666666666666\n",
      "Iteration:  60\n",
      "0.9682777777777778\n",
      "Iteration:  70\n",
      "0.9742222222222222\n",
      "Iteration:  80\n",
      "0.5015\n",
      "Iteration:  90\n",
      "0.9630555555555556\n",
      "Iteration:  100\n",
      "0.9794444444444445\n",
      "Iteration:  110\n",
      "0.9844444444444445\n",
      "Iteration:  120\n",
      "0.9865\n",
      "Iteration:  130\n",
      "0.9881111111111112\n",
      "Iteration:  140\n",
      "0.9896111111111111\n",
      "Iteration:  150\n",
      "0.9903333333333333\n",
      "Iteration:  160\n",
      "0.9911666666666666\n",
      "Iteration:  170\n",
      "0.9918888888888889\n",
      "Iteration:  180\n",
      "0.9921666666666666\n",
      "Iteration:  190\n",
      "0.9927222222222222\n",
      "Iteration:  200\n",
      "0.9932222222222222\n",
      "Iteration:  210\n",
      "0.9938888888888889\n",
      "Iteration:  220\n",
      "0.9940555555555556\n",
      "Iteration:  230\n",
      "0.9944444444444445\n",
      "Iteration:  240\n",
      "0.9946666666666667\n",
      "Iteration:  250\n",
      "0.9951111111111111\n",
      "Iteration:  260\n",
      "0.9954444444444445\n",
      "Iteration:  270\n",
      "0.9955555555555555\n",
      "Iteration:  280\n",
      "0.9956666666666667\n",
      "Iteration:  290\n",
      "0.9958888888888889\n",
      "Iteration:  300\n",
      "0.9961111111111111\n",
      "Iteration:  310\n",
      "0.9961666666666666\n",
      "Iteration:  320\n",
      "0.9962777777777778\n",
      "Iteration:  330\n",
      "0.9964444444444445\n",
      "Iteration:  340\n",
      "0.9965555555555555\n",
      "Iteration:  350\n",
      "0.9966666666666667\n",
      "Iteration:  360\n",
      "0.9967777777777778\n",
      "Iteration:  370\n",
      "0.9968333333333333\n",
      "Iteration:  380\n",
      "0.997\n",
      "Iteration:  390\n",
      "0.9970555555555556\n",
      "Iteration:  400\n",
      "0.9971666666666666\n",
      "Iteration:  410\n",
      "0.9971666666666666\n",
      "Iteration:  420\n",
      "0.9973888888888889\n",
      "Iteration:  430\n",
      "0.9975\n",
      "Iteration:  440\n",
      "0.9975\n",
      "Iteration:  450\n",
      "0.9975\n",
      "Iteration:  460\n",
      "0.9975555555555555\n",
      "Iteration:  470\n",
      "0.9976111111111111\n",
      "Iteration:  480\n",
      "0.9976111111111111\n",
      "Iteration:  490\n",
      "0.9976111111111111\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(trainX, trainY, 0.10, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 18000)\n",
      "[[0. 0. 1. ... 1. 0. 0.]\n",
      " [1. 1. 0. ... 0. 1. 1.]]\n",
      "[0. 1.]\n",
      "[1. 0.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print(trainY)\n",
    "print(trainY[:, 0])\n",
    "print(trainY[:, 17997])\n",
    "print(trainY[:, 17999])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8e34aabc442f0c1116a3baf61b01a37695506cb9ed0318336da2011fc7512b0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('DeepLearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
